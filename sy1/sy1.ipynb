{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(# /**\n",
    "#  *                             _ooOoo_\n",
    "#  *                            o8888888o\n",
    "#  *                            88\" . \"88\n",
    "#  *                            (| -_- |)\n",
    "#  *                            O\\  =  /O\n",
    "#  *                         ____/`---'\\____\n",
    "#  *                       .'  \\\\|     |//  `.\n",
    "#  *                      /  \\\\|||  :  |||//  \\\n",
    "#  *                     /  _||||| -:- |||||-  \\\n",
    "#  *                     |   | \\\\\\  -  /// |   |\n",
    "#  *                     | \\_|  ''\\---/''  |   |\n",
    "#  *                     \\  .-\\__  `-`  ___/-. /\n",
    "#  *                   ___`. .'  /--.--\\  `. . __\n",
    "#  *                .\"\" '<  `.___\\_<|>_/___.'  >'\"\".\n",
    "#  *               | | :  `- \\`.;`\\ _ /`;.`/ - ` : | |\n",
    "#  *               \\  \\ `-.   \\_ __\\ /__ _/   .-` /  /\n",
    "#  *          ======`-.____`-.___\\_____/___.-`____.-'======\n",
    "#  *                             `=---='\n",
    "#  *          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
    "#  *                     佛祖保佑        永无BUG\n",
    "#  *          佛曰:\n",
    "#                   写字楼里写字间，写字间里程序员；\n",
    "#                   程序人员写程序，又拿程序换酒钱。\n",
    "#                   酒醒只在网上坐，酒醉还来网下眠；\n",
    "#                   酒醉酒醒日复日，网上网下年复年。\n",
    "#                   但愿老死电脑间，不愿鞠躬老板前；\n",
    "#                   奔驰宝马贵者趣，公交自行程序员。\n",
    "#                   别人笑我忒疯癫，我笑自己命太贱；\n",
    "#                   不见满街漂亮妹，哪个归得程序员？\n",
    "# \n",
    ")\n",
    "from math import log\n",
    "import operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import datasets\n",
    "def calcSannonEnt(dataSet):\n",
    "    numEntries=len(dataSet)\n",
    "    labelConunts={}\n",
    "    for featVec in dataSet:\n",
    "        currentlabel=featVec[-1]\n",
    "        if  currentlabel not in labelConunts.keys():\n",
    "            labelConunts[currentlabel]=0\n",
    "        labelConunts[currentlabel]+=1\n",
    "    shannoonEnt=0\n",
    "    for key in labelConunts:\n",
    "        prob=float(labelConunts[key]) / numEntries\n",
    "        shannoonEnt-=prob*log(prob,2)\n",
    "    return shannoonEnt\n",
    "\n",
    "#*****************************************************************\n",
    "\n",
    "# def calcShannonEnt(dataSet):                        # 计算数据的信息熵(entropy)\n",
    "#     numEntries = len(dataSet)                       # 数据条数\n",
    "#     labelCounts = {}\n",
    "#     for featVec in dataSet:\n",
    "#         currentLabel = featVec[-1]                      # 每行数据的最后一个字（类别）\n",
    "#         if currentLabel not in labelCounts.keys():\n",
    "#             labelCounts[currentLabel] = 0                     # 这一步其实就是在字典里面初始化每个类别的个数\n",
    "#         labelCounts[currentLabel] += 1                      # 统计有多少个类以及每个类的数量\n",
    "#     shannonEnt = 0\n",
    "#     for key in labelCounts:\n",
    "#         prob=float(labelCounts[key]) / numEntries             # 计算单个类的熵值\n",
    "#         shannonEnt -= prob*log(prob,2)                     # 累加每个类的熵值\n",
    "#     return shannonEnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #创建数据集\n",
    "# def createdataSet1():\n",
    "#     dataSet = [['长','粗','男'],\n",
    "#                    ['短','粗','男'],\n",
    "#                    ['长','细','女'],\n",
    "#                    ['短','细','女'],\n",
    "#                    ['短','粗','女'],\n",
    "#                    ['长','粗','女'],]\n",
    "#     labels = ['头发','声音'] #特征\n",
    "#     return dataSet,labels\n",
    "\n",
    "#**********************************************************\n",
    "\n",
    "\n",
    "def createDataSet1():    # 创造示例数据\n",
    "    dataSet = [['长', '粗', '男'],\n",
    "               ['短', '粗', '男'],\n",
    "               ['短', '粗', '男'],\n",
    "               ['长', '细', '女'],\n",
    "               ['短', '细', '女'],\n",
    "               ['短', '粗', '女'],\n",
    "               ['长', '粗', '女'],\n",
    "               ['长', '粗', '女']]\n",
    "    features = ['头发','声音']  #两个特征\n",
    "    return dataSet,features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #分割数剧集\n",
    "# def splitdataSet(dataSet,axis,value):\n",
    "#     retdataSet = []\n",
    "#     for featVec in dataSet:\n",
    "#         if featVec[axis]==value:\n",
    "#             reducefeatVec = featVec[:axis]\n",
    "#             reducefeatVec.extend(featVec[axis+1:])\n",
    "#             retdataSet.append(reducefeatVec)\n",
    "#     return retdataSet\n",
    "\n",
    "#**********************************************************\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def splitDataSet(dataSet,axis,value): # 按某个特征分类后的数据\n",
    "    retDataSet = []\n",
    "    for featVec in dataSet:\n",
    "        if featVec[axis] == value:\n",
    "            reducedFeatVec = featVec[:axis]\n",
    "            reducedFeatVec.extend(featVec[axis+1:]) # 这两步的操作是没有包括划分的特征属性 很微妙！\n",
    "            retDataSet.append(reducedFeatVec)\n",
    "\n",
    "    return retDataSet\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #选择最优分类特征\n",
    "# def chooseBestFeatureToSplit(dataSet):\n",
    "#     numFeatures = len(dataSet[0])-1\n",
    "#     baseEntropy = calcSannonEnt(dataSet)\n",
    "#     bestInfoGain = 0\n",
    "#     bestFeatture = -1\n",
    "#     for i in range(numFeatures):\n",
    "#         featList = [example[i] for example in dataSet]\n",
    "#         uniqueVals = set(featList)\n",
    "#         newEntropy = 0\n",
    "#         for vaule  in uniqueVals:\n",
    "#           subDataSet = splitdataSet(dataSet,i,vaule)\n",
    "#           prob = len(subDataSet) / float(len(dataSet))\n",
    "#           newEntropy+=prob * calcSannonEnt(subDataSet)\n",
    "#           infoGain = baseEntropy-newEntropy\n",
    "#         if (bestInfoGain>bestInfoGain):\n",
    "#             bestFeatture = infoGain\n",
    "#             bestFeatture = i\n",
    "#     return bestFeatture\n",
    "\n",
    "#****************************************************************************\n",
    "\n",
    "def chooseBestFeatureToSplit(dataSet):  # 选择最优的分类特征\n",
    "    numFeatures = len(dataSet[0]) - 1  # 获得特征的个数  2个\n",
    "    baseEntropy =calcSannonEnt(dataSet)  # 原始的信息熵\n",
    "    bestInfoGain = 0\n",
    "    bestFeature = -1\n",
    "    for i in range(numFeatures): # 遍历两个特征\n",
    "        featList = [example[i] for example in dataSet]\n",
    "        uniqueVals = set(featList) # 引入集合\n",
    "        newEntropy = 0\n",
    "\n",
    "        for value in uniqueVals:\n",
    "            subDataSet = splitDataSet(dataSet, i, value) # 根据某个特征分类后的数据集\n",
    "            prob = len(subDataSet) / float(len(dataSet))\n",
    "            newEntropy += prob*calcSannonEnt(subDataSet)  # 按特征分类后的条件经验熵\n",
    "        infoGain = baseEntropy - newEntropy  # 原始熵与按特征分类后的熵的差值 即按照这个特征划分后的信息增益\n",
    "        if (infoGain > bestInfoGain):   # 若按某特征划分后，熵值减少的最大，则次特征为最优分类特征\n",
    "            bestInfoGain = infoGain\n",
    "            bestFeature = i\n",
    "    return bestFeature # 返回的是最优特征的索引\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def majorityCnt(calssList):\n",
    "#     classCount = {}\n",
    "#     for vote in calssList:\n",
    "#         if vote not in calssList:\n",
    "#             if vote in classCount.keys():\n",
    "#                 classCount[vote]=0\n",
    "#             classCount[vote]+=1\n",
    "#         sortedclassCount = sorted(classCount.items(),key=operator.itemgetter(1),reverse=True)\n",
    "#         print(sortedclassCount)\n",
    "#         return sortedclassCount[0][0]\n",
    "    \n",
    "#**************************************************************************************************\n",
    "\n",
    "def majorityCnt(classList):    # 按分类后类别数量排序，比如：最后分类为2男1女，则判定为男；\n",
    "    classCount = {}\n",
    "    for vote in classList:\n",
    "        if vote not in classCount.keys():\n",
    "            classCount[vote] = 0\n",
    "        classCount[vote] += 1\n",
    "    sortedClassCount = sorted(classCount.items(), key = operator.itemgetter(1),reverse=True)\n",
    "    #print(sortedClassCount)\n",
    "    return sortedClassCount[0][0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 错误示范\n",
    "def createTree(dataSet,labels):\n",
    "    classList = [example[-1] for example in dataSet]\n",
    "    if classList.count(classList[0]) == len(classList):\n",
    "        return classList[0]\n",
    "    if len(dataSet[0]) == 1:\n",
    "        return majorityCnt(classList)\n",
    "    bestFeat = chooseBestFeatureToSplit(dataSet)\n",
    "    bestFeatlabel = labels[bestFeat]\n",
    "\n",
    "    myTree = {bestFeatlabel:{}}\n",
    "    del(labels[bestFeat])\n",
    "    featValues = [ example[bestFeat] for  example in dataSet]\n",
    "    uniqueValues = set(featValues)\n",
    "    for value in uniqueValues:\n",
    "        subLabels = labels[:]\n",
    "        myTree[bestFeatlabel] [value] = createTree(splitDataSet(dataSet,bestFeat,value),subLabels)   \n",
    "    return myTree\n",
    "\n",
    "#********************************************************\n",
    "\n",
    "# 构建决策树(ID3决策树)\n",
    "\n",
    "\n",
    "# def createTree(dataSet, labels):\n",
    "#     classList = [example[-1] for example in dataSet]                  # 类别：男或女\n",
    "#     if classList.count(classList[0]) == len(classList):               # 最终叶子结点中都是一个类别的话就return那个类别\n",
    "#         return classList[0]\n",
    "#     if len(dataSet[0]) == 1:\n",
    "#         return majorityCnt(classList)\n",
    "#     bestFeat = chooseBestFeatureToSplit(dataSet)                        #选择最优特征的索引\n",
    "#     bestFeatLabel = labels[bestFeat]\n",
    "#     myTree = {bestFeatLabel:{}}                                        # 分类结果以字典形式保存\n",
    "#     del(labels[bestFeat])                                              # labels中只有头发这个属性了\n",
    "#     featValues = [example[bestFeat] for example in dataSet]\n",
    "#     uniqueVals = set(featValues)                                        # {'粗'，'细'}、{'长','短'}\n",
    "#     for value in uniqueVals:\n",
    "#         subLabels = labels[:]  \n",
    "#         myTree[bestFeatLabel][value] = createTree(splitDataSet(dataSet, bestFeat, value), subLabels)\n",
    "#     return myTree\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'声音': {'细': '女', '粗': {'头发': {'长': '女', '短': '男'}}}}\n"
     ]
    }
   ],
   "source": [
    "if __name__=='__main__':\n",
    "    dataSet, labels = createDataSet1()  # 创造示列数据\n",
    "    print(createTree(dataSet, labels))  # 输出决策树模型结果"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
